{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "A4.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOB73KsiZJJlJSfIrMWUXsY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/varmadamera/Criminal-Identification-System/blob/master/A4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qz-wASIzslHO"
      },
      "outputs": [],
      "source": [
        "# my first line: Hello A4 "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "my second note."
      ],
      "metadata": {
        "id": "YT7_cbLA4Dgl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# facerec.py\n",
        "import cv2, numpy, os\n",
        "size = 1\n",
        "haar_cascade = cv2.CascadeClassifier('face_cascade.xml')\n",
        "# Part 1: Create fisherRecognizer\n",
        "def train_model():\n",
        "    model = cv2.face.LBPHFaceRecognizer_create()\n",
        "    fn_dir = 'face_samples'\n",
        "    print('Training...')\n",
        "    (images, lables, names, id) = ([], [], {}, 0)\n",
        "    for (subdirs, dirs, files) in os.walk(fn_dir):\n",
        "        # Loop through each folder named after the subject in the photos\n",
        "        for subdir in dirs:\n",
        "            names[id] = subdir\n",
        "            subjectpath = os.path.join(fn_dir, subdir)\n",
        "            # Loop through each photo in the folder\n",
        "            for filename in os.listdir(subjectpath):\n",
        "                # Skip non-image formates\n",
        "                f_name, f_extension = os.path.splitext(filename)\n",
        "                if(f_extension.lower() not in ['.png','.jpg','.jpeg','.gif','.pgm']):\n",
        "                    print(\"Skipping \"+filename+\", wrong file type\")\n",
        "                    continue\n",
        "                path = subjectpath + '/' + filename\n",
        "                lable = id\n",
        "                # Add to training data\n",
        "                images.append(cv2.imread(path, 0))\n",
        "                lables.append(int(lable))\n",
        "            id += 1\n",
        "    # Create a Numpy array from the two lists above\n",
        "    (images, lables) = [numpy.array(lis) for lis in [images, lables]]\n",
        "    # OpenCV trains a model from the images\n",
        "    model.train(images, lables)\n",
        "    return (model, names)\n",
        "# Part 2: Use fisherRecognizer on camera stream\n",
        "def detect_faces(gray_frame):\n",
        "    global size, haar_cascade\n",
        "    # Resize to speed up detection (optinal, change size above)\n",
        "    mini_frame = cv2.resize(gray_frame, (int(gray_frame.shape[1] / size), int(gray_frame.shape[0] / size)))\n",
        "    # Detect faces and loop through each one\n",
        "    faces = haar_cascade.detectMultiScale(mini_frame)\n",
        "    return faces\n",
        "def recognize_face(model, frame, gray_frame, face_coords, names):\n",
        "    (img_width, img_height) = (112, 92)\n",
        "    recognized = []\n",
        "    recog_names = []\n",
        "    for i in range(len(face_coords)):\n",
        "        face_i = face_coords[i]\n",
        "        # Coordinates of face after scaling back by `size`\n",
        "        (x, y, w, h) = [v * size for v in face_i]\n",
        "        face = gray_frame[y:y + h, x:x + w]\n",
        "        face_resize = cv2.resize(face, (img_width, img_height))\n",
        "        # Try to recognize the face\n",
        "        (prediction, confidence) = model.predict(face_resize)\n",
        "        # print(prediction, confidence)\n",
        "        if (confidence<95 and names[prediction] not in recog_names):\n",
        "            cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 0, 255), 2)\n",
        "            recog_names.append(names[prediction])\n",
        "            recognized.append((names[prediction].capitalize(), confidence))\n",
        "        elif (confidence >= 95):\n",
        "            cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
        "\n",
        "    return (frame, recognized)"
      ],
      "metadata": {
        "id": "7on5jJwV-t1I"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}